+ GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval
+ Synergizing large language models and pre-trained smaller models for conversational intent discovery
+ Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models
+ Small Models are Valuable Plug-ins for Large Language Models
+ Improving In-Context Learning with Small Language Model Ensembles
+ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought
+ Synergistic Weak-Strong Collaboration by Aligning Preferences
+ Synergistic Augmentation: Enhancing Cross-Domain Zero-Shot Slot Filling with Small Model-Assisted Large Language Models
+ Mixture of Small and Large Models for {C}hinese Spelling Check
+ Flipping {{Knowledge Distillation}}: {{Leveraging Small Models}}' {{Expertise}} to {{Enhance LLMs}} in {{Text Matching}}}
+ ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports
+ CaLM: Contrasting Large and Small Language Models to Verify Grounded Generation
+ Combining small language models and large language models for zero-shot NL2SQL
+ Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative Approach to Few-shot Multimodal Dialogue Intention Recognition
+ Collab-rag: Boosting retrieval-augmented generation for complex question answering via white-box and black-box llm collaboration
+ General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction
+ Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face
+ TrajAgent: An LLM-based Agent Framework for Automated Trajectory Modeling via Collaboration of Large and Small Models
+ A little help goes a long way: Efficient llm training by leveraging small lms
+ Perplexed by perplexity: Perplexity-based data pruning with small reference models
+ Learning to Grow Pretrained Models for Efficient Transformer Training
+ Efficient Construction of Model Family through Progressive Training Using Model Expansion
+ Scaling Smart: Accelerating Large Language Model Pre-Training with Small Model Initialization
+ Pre-training Distillation for Large Language Models: A Design Space Exploration
+ Distilled Pretraining: A modern lens of Data, In-Context Learning and Test-Time Scaling
+ Mini{PLM}: Knowledge Distillation for Pre-training Language Models
+ Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data
+ On efficient distillation from LLMs to SLMs
+ Synergizing large language models and pre-trained smaller models for conversational intent discovery
+ Hawkeye: Model Collaboration for Efficient Reasoning
+ Large Model Strategic Thinking, Small Model Efficiency: Transferring Theory of Mind in Large Language Models
+ C2KD: Cross-layer and Cross-head Knowledge Distillation for Small Language Model-based Recommendation
+ Distilling llm agent into small models with retrieval and code tools
+ Collaboration of Large Language Models and Small Recommendation Models for Device-Cloud Recommendation
+ SmallPlan: Leverage Small Language Models for Sequential Path Planning with Simulation-Powered, LLM-Guided Distillation
+ Think big, generate quick: Llm-to-slm for fast autoregressive decoding
+ Train Small, Infer Large: Memory-Efficient Lo{RA} Training for Large Language Models
+ Litemoe: Customizing on-device LLM serving via proxy submodel tuning
+ Gatekeeper: Improving Model Cascades Through Confidence Tuning
+ G-Boost: Boosting Private SLMs with General LLMs
+ Frugal{GPT}: How to Use Large Language Models While Reducing Cost and Improving Performance
+ Route{LLM}: Learning to Route {LLM}s from Preference Data
+ Privacy-preserved LLM Cascade via CoT-enhanced Policy Learning
+ Large Language Model Cascades with Mixture of Thought Representations for Cost-Efficient Reasoning
+ Hybrid slm and llm for edge-cloud collaborative inference
+ Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When and What to Retrieve for {LLM}s
+ {CITER}: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing
+ R2R: Efficiently Navigating Divergent Reasoning Paths with Small-Large Model Token Routing
+ MixLLM: Dynamic Routing in Mixed Large Language Models
+ MoE $^2$: Optimizing Collaborative Inference for Edge Large Language Models
+ Cross-Attention Speculative Decoding
+ Scaling Speculative Decoding with Lookahead Reasoning
+ Accelerating Diffusion LLMs via Adaptive Parallel Decoding
+ Llmcad: Fast and scalable on-device large language model inference
+ PICE: A semantic-driven progressive inference system for LLM serving in cloud-edge networks
+ Fast and slow generating: An empirical study on large and small language models collaborative decoding
+ {BEST}-Route: Adaptive {LLM} Routing with Test-Time Optimal Compute
+ AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks
+ Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques
+ Casper: {Prompt} {Sanitization} for {Protecting} {User} {Privacy} in {Web}-{Based} {Large} {Language} {Models}
+ Neural {Text} {Sanitization} with {Explicit} {Measures} of {Privacy} {Risk}
+ Guarding Your Conversations: Privacy Gatekeepers for Secure Interactions with Cloud-Based AI Models
+ Anonymizing medical documents with local, privacy preserving large language models: {The} {LLM}-{Anonymizer}
+ Can {LLM}s get help from other {LLM}s without revealing private information?
+ CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following
+ CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs
+ Privacy-preserved LLM Cascade via CoT-enhanced Policy Learning
+ {R}emote{RAG}: A Privacy-Preserving {LLM} Cloud {RAG} Service
+ Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting
+ Mini{LLM}: Knowledge Distillation of Large Language Models
+ {L}lama{D}uo: {LLMO}ps Pipeline for Seamless Migration from Service {LLM}s to Small-Scale Local {LLM}s
+ {DRAG}: Distilling {RAG} for {SLM}s from {LLM}s to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation
+ Towards Privacy-Preserving and Personalized Smart Homes via Tailored Small Language Models
+ Enabling on-device large language model personalization with self-supervised data selection and synthesis
+ Beyond answers: Transferring reasoning capabilities to smaller llms using multi-teacher knowledge distillation
+ Small Models Struggle to Learn from Strong Reasoners
+ Advantage-Guided Distillation for Preference Alignment in Small Language Models
+ {{CombLM}}: {{Adapting Black-Box Language Models}} through {{Small Fine-Tuned Models}}
+ {{CPT}}: {{Consistent Proxy Tuning}} for {{Black-box Optimization}}
+ {G}rad{OT}: Training-free Gradient-preserving Offsite-tuning for Large Language Models
+ {{GOOD}}: {{Decoding-Time Black-Box LLM Alignment}}
+ {{PHLoRA}}: Data-Free {{Post-hoc Low-Rank Adapter}} Extraction from Full-Rank Checkpoint
+ {{LoRASuite}}: {{Efficient LoRA Adaptation Across Large Language Model Upgrades}}
+ Lo{RA}-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation
+ Trans-LoRA: towards data-free Transferable Parameter Efficient Finetuning
+ Cross-{{LoRA}}: {{A Data-Free LoRA Transfer Framework}} across {{Heterogeneous LLMs}}
+ CrossLM: A Data-Free Collaborative Fine-Tuning Framework for Large and Small Language Models
+ FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models
+ {{FedPT}}: {{Federated Proxy-Tuning}} of {{Large Language Models}} on {{Resource-Constrained Edge Devices}}
+ FedPFT: Federated Proxy Fine-Tuning of Foundation Models
+ {{FDLoRA}}: {{Personalized Federated Learning}} of {{Large Language Model}} via {{Dual LoRA Tuning}}
+ Automated {{Federated Pipeline}} for {{Parameter-Efficient Fine-Tuning}} of {{Large Language Models}}
+ {FL}o{RA}: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations
+ Purifying large language models by ensembling a small language model
+ Decoding-time language model alignment with multiple objectives
+ Offset Unlearning for Large Language Models
+ Weak-to-Strong Jailbreaking on Large Language Models
+ Llama Guard 1,2,3,4
+ Prompt Guard
+ Enhancing guardrails for safe and secure healthcare ai
+ Shieldgemma: Generative ai content moderation based on gemma
+ Shieldgemma 2: Robust and tractable image content moderation
+ Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms
+ {T}hink{G}uard: Deliberative Slow Thinking Leads to Cautious Guardrails
+ MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents
+ When in Doubt, Cascade: Towards Building Efficient and Capable Guardrails
+ Llamafirewall: An open source guardrail system for building secure ai agents
+ 
  
